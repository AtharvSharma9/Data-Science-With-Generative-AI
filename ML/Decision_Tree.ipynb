{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?**\n",
        "\n",
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. In the context of classification, it works by recursively partitioning the data into subsets based on the values of the input features. It creates a tree-like structure where each internal node represents a test on an attribute, each branch represents an outcome of the test, and each leaf node represents a class label.\n",
        "\n",
        "Here's a breakdown of how it works for classification:\n",
        "\n",
        "1. Splitting: The algorithm starts with the entire dataset as the root node. It then selects the \"best\" attribute to split the data based on a criterion like Gini impurity or information gain. The goal is to choose the attribute that best separates the data into different classes.\n",
        "2. Recursive Partitioning: The dataset is split into subsets based on the values of the chosen attribute. This process is repeated recursively for each subset, creating child nodes.\n",
        "3. Stopping Criteria: The recursive partitioning stops when a stopping criterion is met. This could be when all instances in a node belong to the same class, when a predefined maximum depth is reached, or when the number of instances in a node falls below a certain threshold.\n",
        "4. Leaf Nodes: The final nodes that are not split further are called leaf nodes. Each leaf node is assigned a class label based on the majority class of the instances in that node.\n",
        "5. Classification: To classify a new instance, you traverse the tree from the root node down to a leaf node by following the branches corresponding to the instance's attribute values. The class label of the leaf node is the predicted class for the instance."
      ],
      "metadata": {
        "id": "erORpP44PBJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?**\n",
        "\n",
        "Gini Impurity and Entropy are two common metrics used in Decision Trees to measure the impurity or disorder of a set of data. The goal of the Decision Tree algorithm is to find splits that minimize the impurity in the resulting subsets.\n",
        "\n",
        "Here's an explanation of each and how they impact splits:\n",
        "\n",
        "* Gini Impurity:\n",
        "  1. Concept: Gini impurity measures the probability of misclassifying a randomly chosen element in the dataset if it were randomly labeled according to the distribution of classes in the subset. A lower Gini impurity indicates a purer subset (more instances belong to the same class).\n",
        "  2. Formula: Gini Impurity = $1 - \\sum_{i=1}^{C} (p_i)^2$$1 - \\sum_{i=1}^{C} (p_i)^2$, where $C$$C$ is the number of classes and $p_i$$p_i$ is the proportion of instances belonging to class $i$$i$ in the subset.\n",
        "  3. Impact on Splits: When deciding on a split, the Decision Tree calculates the Gini impurity of the original set and the weighted average of the Gini impurity of the resulting subsets after a potential split. The algorithm chooses the split that results in the largest reduction in Gini impurity (or the largest \"Gini Gain\"). This means the split that best separates the classes is preferred.\n",
        "* Entropy:\n",
        "  1. Concept: Entropy is a measure of the randomness or uncertainty in a set of data. In the context of Decision Trees, it measures the unpredictability of the class label for a randomly chosen instance in a subset. Lower entropy indicates less uncertainty and a purer subset.\n",
        "  2. Formula: Entropy = $-\\sum_{i=1}^{C} p_i \\log_2(p_i)$$-\\sum_{i=1}^{C} p_i \\log_2(p_i)$, where $C$$C$ is the number of classes and $p_i$$p_i$ is the proportion of instances belonging to class $i$$i$ in the subset.\n",
        "  3. Impact on Splits: Similar to Gini impurity, the Decision Tree calculates the entropy of the original set and the weighted average of the entropy of the resulting subsets after a potential split. The algorithm chooses the split that results in the largest reduction in entropy (or the largest \"Information Gain\"). This also favors splits that effectively separate the classes.\n",
        "\n",
        "**How they Impact Splits:**\n",
        "\n",
        "Both Gini Impurity and Entropy serve the same fundamental purpose: to quantify the \"mixed-up-ness\" of the classes within a subset of data. The Decision Tree uses these measures to evaluate potential splits at each node. The split that minimizes the impurity (either Gini or Entropy) in the resulting child nodes is chosen as the best split. This process is repeated recursively until a stopping criterion is met."
      ],
      "metadata": {
        "id": "ixQqLpD3PEIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.**\n",
        "\n",
        "Pre-pruning and post-pruning are techniques used to prevent overfitting in Decision Trees by controlling the complexity of the tree.\n",
        "\n",
        "Here's the difference and an advantage of each:\n",
        "\n",
        "* **Pre-Pruning (Early Stopping):**\n",
        "  1. **Difference:** This technique stops the tree building process before it has fully grown. It sets criteria to decide whether to split a node or make it a leaf node. Common criteria include:\n",
        "\n",
        "    ->Maximum depth of the tree.\n",
        "\n",
        "    ->Minimum number of samples required to split an internal node.\n",
        "\n",
        "    ->Minimum number of samples required in a leaf node.\n",
        "\n",
        "    ->A threshold for the impurity measure (e.g., stop splitting if the impurity is below a certain value).\n",
        "    \n",
        "  2. **Practical Advantage:** Pre-pruning can be computationally faster than post-pruning because it avoids building the full, potentially complex tree. This can be particularly beneficial for very large datasets.\n",
        "* **Post-Pruning (Late Stopping):**\n",
        "  1. **Difference:** This technique involves building the full Decision Tree first and then pruning (removing) branches or nodes from the fully grown tree. This is typically done by evaluating the performance of the tree on a validation set and removing parts that do not contribute to improving accuracy or even decrease it. Cost-complexity pruning (also known as weakest link pruning) is a common post-pruning technique.\n",
        "  2. **Practical Advantage:** Post-pruning can sometimes lead to a more optimal tree than pre-pruning. This is because it allows the tree to explore all possible splits and then strategically remove those that are not beneficial, potentially uncovering valuable structures that might have been missed with early stopping criteria.\n"
      ],
      "metadata": {
        "id": "79Bjd92pQgSw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52a7485c"
      },
      "source": [
        "**Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?**\n",
        "\n",
        "Information Gain is a metric used in Decision Trees, particularly with the Entropy impurity measure, to determine the effectiveness of a split. It quantifies the reduction in entropy (or increase in information) achieved by splitting a dataset based on an attribute. The formula is:\n",
        "\n",
        "Information Gain (S, A) = Entropy(S) - $\\sum_{v \\in \\text{Values(A)}} \\frac{|S_v|}{|S|}$ * Entropy($S_v$)\n",
        "\n",
        "Where S is the parent node, A is the attribute, Values(A) are attribute values, Sv is the subset for value v, |Sv| is the count in Sv, |S| is the count in S, Entropy(S) is parent entropy, and Entropy(Sv) is child entropy for value v.\n",
        "\n",
        "Information Gain is important because the Decision Tree algorithm selects the attribute with the highest Information Gain for splitting a node. This is because a higher Information Gain indicates that the split more effectively separates the data into subsets with more homogeneous class labels, leading to a more effective classification tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10d6a89c"
      },
      "source": [
        "**Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?**\n",
        "\n",
        "Decision Trees are versatile and widely used in various real-world applications due to their interpretability and ease of understanding.\n",
        "\n",
        "Here are some common applications:\n",
        "\n",
        "*   **Medical Diagnosis:** Decision Trees can be used to help diagnose diseases based on symptoms and patient data.\n",
        "*   **Credit Risk Assessment:** Financial institutions use Decision Trees to assess the creditworthiness of loan applicants.\n",
        "*   **Customer Relationship Management (CRM):** They can be used to predict customer behavior, identify potential churn, and personalize marketing campaigns.\n",
        "*   **Fraud Detection:** Decision Trees can help identify fraudulent transactions in finance or other domains.\n",
        "*   **Spam Filtering:** Email providers use Decision Trees to classify emails as spam or not spam.\n",
        "*   **Bioinformatics:** They are used for analyzing biological data, such as classifying genes or proteins.\n",
        "*   **Manufacturing and Quality Control:** Decision Trees can help identify factors contributing to defects or optimize production processes.\n",
        "\n",
        "**Main Advantages of Decision Trees:**\n",
        "\n",
        "*   **Easy to Understand and Interpret:** The tree-like structure makes it easy to visualize and understand the decision-making process.\n",
        "*   **Handle Both Numerical and Categorical Data:** Decision Trees can work with different types of data without extensive preprocessing.\n",
        "*   **Require Little Data Preparation:** They don't require feature scaling or normalization.\n",
        "*   **Can Handle Multi-Output Problems:** They can predict multiple target variables simultaneously.\n",
        "*   **Non-linear Relationships:** They can capture non-linear relationships between features and the target variable.\n",
        "\n",
        "**Main Limitations of Decision Trees:**\n",
        "\n",
        "*   **Prone to Overfitting:** Without proper pruning or setting of parameters, Decision Trees can become overly complex and perform poorly on unseen data.\n",
        "*   **Instability:** Small changes in the data can lead to significant changes in the tree structure.\n",
        "*   **Bias Towards Features with More Levels:** Decision Trees can be biased towards attributes with a larger number of distinct values.\n",
        "*   **Cannot Extrapolate:** They can only predict within the range of the training data.\n",
        "*   **May Not Be Optimal Globally:** The greedy approach of selecting the best split at each node doesn't guarantee a globally optimal tree."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: Write a Python program to:**\n",
        "\n",
        "**● Load the Iris Dataset**\n",
        "\n",
        "**● Train a Decision Tree Classifier using the Gini criterion**\n",
        "\n",
        "**● Print the model’s accuracy and feature importances**"
      ],
      "metadata": {
        "id": "v23WqXOXTTwj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "ba2127da",
        "outputId": "fbe63b27-46fc-48e4-fdfa-4c81afbeb70f"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris Dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using the Gini criterion\n",
        "# The default criterion for DecisionTreeClassifier is 'gini'\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print the feature importances\n",
        "feature_importances = pd.DataFrame({'feature': iris.feature_names, 'importance': clf.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "print(\"\\nFeature Importances:\")\n",
        "display(feature_importances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0000\n",
            "\n",
            "Feature Importances:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             feature  importance\n",
              "2  petal length (cm)    0.906143\n",
              "3   petal width (cm)    0.077186\n",
              "1   sepal width (cm)    0.016670\n",
              "0  sepal length (cm)    0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19571428-815b-48c0-a740-cb0b481700fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>petal length (cm)</td>\n",
              "      <td>0.906143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>petal width (cm)</td>\n",
              "      <td>0.077186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sepal width (cm)</td>\n",
              "      <td>0.016670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sepal length (cm)</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19571428-815b-48c0-a740-cb0b481700fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19571428-815b-48c0-a740-cb0b481700fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19571428-815b-48c0-a740-cb0b481700fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d24e7cd2-c9c5-40dc-9db8-3351c6ca7796\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d24e7cd2-c9c5-40dc-9db8-3351c6ca7796')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d24e7cd2-c9c5-40dc-9db8-3351c6ca7796 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d021ae4d-f935-48bb-add5-f3fe8d8d6a10\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_importances')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d021ae4d-f935-48bb-add5-f3fe8d8d6a10 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_importances');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_importances",
              "summary": "{\n  \"name\": \"feature_importances\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"petal width (cm)\",\n          \"sepal length (cm)\",\n          \"petal length (cm)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4386842003259008,\n        \"min\": 0.0,\n        \"max\": 0.9061433868879218,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.07718647349965893,\n          0.0,\n          0.9061433868879218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12c924fe"
      },
      "source": [
        "**Question 7: Write a Python program to:**\n",
        "\n",
        "**● Load the Iris Dataset**\n",
        "\n",
        "**● Train a Decision Tree Classifier with max\\_depth=3 and compare its accuracy to a fully-grown tree.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7378c794",
        "outputId": "76754d77-1faf-4f16-e29a-0ef2d0710386"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris Dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a fully-grown Decision Tree Classifier (default behavior)\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set with the fully-grown tree\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the fully-grown tree\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "print(f\"Accuracy of the fully-grown tree: {accuracy_full:.4f}\")\n",
        "\n",
        "# Train a Decision Tree Classifier with max_depth=3\n",
        "clf_pruned = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_pruned.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set with the pruned tree\n",
        "y_pred_pruned = clf_pruned.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the pruned tree\n",
        "accuracy_pruned = accuracy_score(y_test, y_pred_pruned)\n",
        "print(f\"Accuracy of the tree with max_depth=3: {accuracy_pruned:.4f}\")\n",
        "\n",
        "# Comparison\n",
        "print(\"\\nComparison of Accuracies:\")\n",
        "if accuracy_pruned > accuracy_full:\n",
        "    print(\"The tree with max_depth=3 has higher accuracy on the test set.\")\n",
        "elif accuracy_pruned < accuracy_full:\n",
        "    print(\"The fully-grown tree has higher accuracy on the test set.\")\n",
        "else:\n",
        "    print(\"Both trees have the same accuracy on the test set.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the fully-grown tree: 1.0000\n",
            "Accuracy of the tree with max_depth=3: 1.0000\n",
            "\n",
            "Comparison of Accuracies:\n",
            "Both trees have the same accuracy on the test set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eedc1e2c"
      },
      "source": [
        "**Question 8: Write a Python program to:**\n",
        "\n",
        "**● Load a Regression Dataset (using California Housing as Boston Housing is deprecated)**\n",
        "\n",
        "**● Train a Decision Tree Regressor**\n",
        "\n",
        "**● Print the Mean Squared Error (MSE) and feature importances**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "15432167",
        "outputId": "a9162674-7192-4922-d2c0-f5b67a01698d"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Load the California Housing Dataset (as Boston Housing is deprecated)\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Print the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "\n",
        "# Print the feature importances\n",
        "feature_importances = pd.DataFrame({'feature': housing.feature_names, 'importance': regressor.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
        "print(\"\\nFeature Importances:\")\n",
        "display(feature_importances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.4952\n",
            "\n",
            "Feature Importances:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      feature  importance\n",
              "0      MedInc    0.528509\n",
              "5    AveOccup    0.130838\n",
              "6    Latitude    0.093717\n",
              "7   Longitude    0.082902\n",
              "2    AveRooms    0.052975\n",
              "1    HouseAge    0.051884\n",
              "4  Population    0.030516\n",
              "3   AveBedrms    0.028660"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d244dec4-e7ce-41d0-a880-45260736746d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MedInc</td>\n",
              "      <td>0.528509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AveOccup</td>\n",
              "      <td>0.130838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Latitude</td>\n",
              "      <td>0.093717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Longitude</td>\n",
              "      <td>0.082902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AveRooms</td>\n",
              "      <td>0.052975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HouseAge</td>\n",
              "      <td>0.051884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Population</td>\n",
              "      <td>0.030516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AveBedrms</td>\n",
              "      <td>0.028660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d244dec4-e7ce-41d0-a880-45260736746d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d244dec4-e7ce-41d0-a880-45260736746d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d244dec4-e7ce-41d0-a880-45260736746d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9c5a9df6-5564-4537-9502-8d7b88764ec0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c5a9df6-5564-4537-9502-8d7b88764ec0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9c5a9df6-5564-4537-9502-8d7b88764ec0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ce972f72-a78c-483f-be44-682dfc94a1d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_importances')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ce972f72-a78c-483f-be44-682dfc94a1d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('feature_importances');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "feature_importances",
              "summary": "{\n  \"name\": \"feature_importances\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"AveOccup\",\n          \"HouseAge\",\n          \"MedInc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16662480399944724,\n        \"min\": 0.02866045788296106,\n        \"max\": 0.5285090936963706,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.13083767753210346,\n          0.05188353710616045,\n          0.5285090936963706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0276ef1"
      },
      "source": [
        "**Question 9: Write a Python program to:**\n",
        "\n",
        "**● Load the Iris Dataset**\n",
        "\n",
        "**● Tune the Decision Tree’s max\\_depth and min\\_samples\\_split using GridSearchCV**\n",
        "\n",
        "**● Print the best parameters and the resulting model accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d92f06db",
        "outputId": "a0a2dc88-6d98-4bca-f2ed-3ef02afb335b"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris Dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid to tune\n",
        "param_grid = {\n",
        "    'max_depth': [None, 2, 3, 4, 5],\n",
        "    'min_samples_split': [2, 5, 10, 20]\n",
        "}\n",
        "\n",
        "# Create a Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"Best parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_dt = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "y_pred_best = best_dt.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the best model on the test set\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"\\nAccuracy of the best model on the test set: {accuracy_best:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found by GridSearchCV:\n",
            "{'max_depth': None, 'min_samples_split': 2}\n",
            "\n",
            "Accuracy of the best model on the test set: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values.**\n",
        "\n",
        "**Explain the step-by-step process you would follow to:**\n",
        "\n",
        "**● Handle the missing values**\n",
        "\n",
        "**● Encode the categorical features**\n",
        "\n",
        "**● Train a Decision Tree model**\n",
        "\n",
        "**● Tune its hyperparameters**\n",
        "\n",
        "**● Evaluate its performance**\n",
        "\n",
        "**And describe what business value this model could provide in the real-world\n",
        "setting.**"
      ],
      "metadata": {
        "id": "DSVbYM9HWJP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score # Import accuracy_score\n",
        "from sklearn.datasets import load_iris # Import load_iris for demonstration\n",
        "\n",
        "# Example: load dataset\n",
        "# df = pd.read_csv(\"healthcare_data.csv\")\n",
        "# X = df.drop(\"disease\", axis=1)\n",
        "# y = df[\"disease\"]\n",
        "\n",
        "# Load the Iris dataset for demonstration purposes since the healthcare data is not available\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names) # Convert to DataFrame\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identify feature types\n",
        "# Now X is a DataFrame, so select_dtypes will work\n",
        "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "\n",
        "# Preprocessing: imputation + encoding\n",
        "# Using median for numerical imputation and most_frequent for categorical imputation\n",
        "# Note: For the Iris dataset, there are no missing values, but this demonstrates the process\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_features),\n",
        "        (\"cat\", categorical_transformer, cat_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Model pipeline\n",
        "clf = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    \"classifier__max_depth\": [3, 5, 7, None],\n",
        "    \"classifier__min_samples_split\": [2, 5, 10],\n",
        "    \"classifier__min_samples_leaf\": [1, 2, 5],\n",
        "    \"classifier__criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "# Changed scoring to 'accuracy' as roc_auc is not directly suitable for multi-class by default\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluation\n",
        "y_pred = best_model.predict(X_test)\n",
        "# y_proba = best_model.predict_proba(X_test)[:, 1] # This line is for binary classification\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate accuracy for multi-class problem\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy on the test set: {accuracy:.4f}\")\n",
        "\n",
        "# Note: For a multi-class problem like Iris, calculating a single ROC-AUC score directly\n",
        "# is not straightforward. You would typically calculate per-class ROC-AUC or use\n",
        "# strategies like 'ovo' (one-vs-one) or 'ovr' (one-vs-rest) if needed for this metric.\n",
        "# For the binary classification task described in the question, roc_auc_score would be appropriate.\n",
        "# print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "\n",
        "print(\"\\nBest Params:\", grid_search.best_params_)\n",
        "\n",
        "# Business Value Description (as requested in Question 10)\n",
        "print(\"\\nPotential Business Value in Healthcare:\")\n",
        "print(\"- **Early Disease Detection:** The model can help identify patients at high risk of having the disease, enabling earlier diagnosis and intervention.\")\n",
        "print(\"- **Improved Patient Outcomes:** Early detection and personalized treatment based on risk can lead to better health outcomes for patients.\")\n",
        "print(\"- **Optimized Resource Allocation:** By identifying high-risk patients, healthcare providers can prioritize resources (e.g., screening, specialist appointments) more effectively.\")\n",
        "print(\"- **Reduced Healthcare Costs:** Early intervention can potentially prevent the progression of the disease, reducing the need for more expensive treatments later on.\")\n",
        "print(\"- **Personalized Medicine:** Understanding the key features that contribute to disease prediction can inform personalized treatment plans.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmk80o31WFBc",
        "outputId": "6e77f2ac-1693-445c-d236-b8d6bf5c2c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "Accuracy on the test set: 1.0000\n",
            "\n",
            "Best Params: {'classifier__criterion': 'gini', 'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}\n",
            "\n",
            "Potential Business Value in Healthcare:\n",
            "- **Early Disease Detection:** The model can help identify patients at high risk of having the disease, enabling earlier diagnosis and intervention.\n",
            "- **Improved Patient Outcomes:** Early detection and personalized treatment based on risk can lead to better health outcomes for patients.\n",
            "- **Optimized Resource Allocation:** By identifying high-risk patients, healthcare providers can prioritize resources (e.g., screening, specialist appointments) more effectively.\n",
            "- **Reduced Healthcare Costs:** Early intervention can potentially prevent the progression of the disease, reducing the need for more expensive treatments later on.\n",
            "- **Personalized Medicine:** Understanding the key features that contribute to disease prediction can inform personalized treatment plans.\n"
          ]
        }
      ]
    }
  ]
}