{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:** Compare and contrast NLTK and spaCy in terms of features, ease of use,\n",
        "and performance.\n",
        "\n",
        "1. Comparison of NLTK and spaCy ( Overview )\n",
        "\n",
        "* NLTK (Natural Language Toolkit)\n",
        "\n",
        "  * A traditional, academic-focused NLP library.\n",
        "\n",
        "  * Designed for teaching, research, and experimentation.\n",
        "\n",
        "* spaCy\n",
        "\n",
        "  * An industrial-strength NLP library.\n",
        "\n",
        "  * Designed for speed, production use, and real-world applications.\n",
        "\n",
        "2. Feature Comparison\n",
        "\n",
        "| Feature | NLTK | spaCy |\n",
        "|---|---|---|\n",
        "| Design Purpose | Educational, research | Industrial, production |\n",
        "| Tokenization | Good, flexible | Very fast and accurate |\n",
        "| POS Tagging | Traditional ML models | State-of-the-art neural models |\n",
        "| NER (Named Entity Recognition) | Weak, basic | Very strong, high accuracy |\n",
        "| Dependency Parsing | Basic | Excellent, optimized parser |\n",
        "| Word Vectors | Must integrate separately | Built-in support |\n",
        "| Corpora | Comes with many datasets | Minimal built-in corpora |\n",
        "\n",
        "3. Ease of Use\n",
        "NLTK\n",
        "\n",
        "  * Easy for beginners.\n",
        "\n",
        "  * Lots of tutorials, corpora, and educational resources.\n",
        "\n",
        "  * But requires more manual coding for advanced tasks.\n",
        "\n",
        "spaCy\n",
        "\n",
        "  * Simple API and modern architecture.\n",
        "\n",
        "  * Many tasks work â€œout of the boxâ€.\n",
        "\n",
        "  * But fewer built-in corpora for learning.\n",
        "\n",
        "4. Performance\n",
        "NLTK\n",
        "\n",
        "  * Slower because many algorithms are older and not optimized.\n",
        "\n",
        "  * Best suited for smaller experiments, not high-speed production.\n",
        "\n",
        "spaCy\n",
        "\n",
        "  * Much faster, written in optimized Cython.\n",
        "\n",
        "  * Uses neural models designed for production.\n",
        "\n",
        "  * Handles large datasets efficiently."
      ],
      "metadata": {
        "id": "EunJRz7fnUoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2:** What is TextBlob and how does it simplify common NLP tasks like\n",
        "sentiment analysis and translation?\n",
        "\n",
        "**What is TextBlob?**\n",
        "\n",
        "TextBlob is a simple and user-friendly Python library built on top of NLTK and Pattern, designed to make common NLP tasks easier for beginners and rapid application development.\n",
        "\n",
        "It provides a clean, high-level API for processing textual data without requiring deep knowledge of NLP algorithms.\n",
        "\n",
        "**How TextBlob Simplifies NLP Tasks**\n",
        "1. Sentiment Analysis\n",
        "\n",
        "  * TextBlob provides a built-in sentiment analyzer.\n",
        "\n",
        "  * It returns polarity (â€“1 to +1) and subjectivity (0 to 1) with just one line of code.\n",
        "\n",
        "  * No training, preprocessing, or manual model handling is required.\n",
        "\n",
        "  Example:"
      ],
      "metadata": {
        "id": "LDmXAJRdo-co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = TextBlob(\"I love this app!\")\n",
        "print(text.sentiment)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nhuEHLqpR9a",
        "outputId": "c6549cde-f886-4440-c427-701cc3af7aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.625, subjectivity=0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Translation\n",
        "\n",
        "  * TextBlob uses an internal API (Pattern/Google Translate backend) to translate text.\n",
        "\n",
        "  * Again, only one line of code is needed.\n",
        "\n",
        "3. Other Simplified NLP Tasks\n",
        "\n",
        "TextBlob also makes these easy:\n",
        "\n",
        "  * Tokenization (text.words, text.sentences)\n",
        "\n",
        "  * POS tagging (text.tags)\n",
        "\n",
        "  * Noun phrase extraction (text.noun_phrases)\n",
        "\n",
        "  * Spell correction (text.correct())"
      ],
      "metadata": {
        "id": "buRHPj8VpYPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3:** Explain the role of Standford NLP in academic and industry NLP Projects.\n",
        "\n",
        "Role of Stanford NLP in Academic and Industry NLP Projects\n",
        "\n",
        "Stanford NLP (Stanford CoreNLP) is a powerful suite of natural language processing tools developed by Stanford University. It provides state-of-the-art algorithms for various language analysis tasks.\n",
        "\n",
        "1. Role in Academic Research\n",
        "\n",
        "a) Benchmark for NLP tasks\n",
        "\n",
        "Stanford NLP provides high-quality models for POS tagging, NER, parsing, and sentiment analysis, which serve as benchmarks for research studies.\n",
        "\n",
        "b) Linguistically accurate models\n",
        "\n",
        "The tools are developed with strong linguistic theories, making them highly suitable for linguistic research, corpus studies, and computational linguistics projects.\n",
        "\n",
        "c) Multilingual support for cross-linguistic research\n",
        "\n",
        "It supports many languages, helping researchers work on multilingual NLP experiments.\n",
        "\n",
        "d) Open-source and widely cited\n",
        "\n",
        "Stanford NLP tools are open-source and extensively referenced, making them a reliable choice for academic publications.\n",
        "\n",
        "2. Role in Industry Applications\n",
        "\n",
        "a) Production-grade NLP pipeline\n",
        "\n",
        "Companies use CoreNLP for tasks like:\n",
        "\n",
        "* Named Entity Recognition\n",
        "\n",
        "* Sentiment Analysis\n",
        "\n",
        "* Dependency Parsing\n",
        "\n",
        "* Coreference Resolution\n",
        "\n",
        "It provides stable, mature, and accurate components.\n",
        "\n",
        "b) Good for rule-based + statistical hybrid systems\n",
        "\n",
        "Industry workflows often require combining linguistic rules with machine learning, which CoreNLP supports well.\n",
        "\n",
        "c) Integration with enterprise systems\n",
        "\n",
        "CoreNLP can be deployed as a server, consumed through REST APIs, and integrated into:\n",
        "\n",
        "* Customer service chatbots\n",
        "\n",
        "* Search engines\n",
        "\n",
        "* Document analysis systems\n",
        "\n",
        "* Information extraction pipelines\n",
        "\n",
        "d) Strong performance for structured text extraction\n",
        "\n",
        "Industries like finance, healthcare, and legal use CoreNLP to extract information from large volumes of unstructured text."
      ],
      "metadata": {
        "id": "c4RP-uGrppx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** Describe the architecture and functioning of a Recurrent Natural Network (RNN).\n",
        "\n",
        "Recurrent Neural Network (RNN): Architecture and Functioning\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a type of neural network designed to process sequential data such as text, speech, or time-series. Unlike traditional neural networks, RNNs have a memory of previous inputs.\n",
        "\n",
        "1. Architecture of an RNN\n",
        "\n",
        "a) Input Layer\n",
        "\n",
        "* Takes sequential data as input.\n",
        "\n",
        "* Example: words in a sentence â†’ one word at each time step t.\n",
        "\n",
        "b) Hidden Layer (core of RNN)\n",
        "\n",
        "* Contains recurrent connections, meaning the output of the hidden layer at time t is fed back as input at time t+1.\n",
        "\n",
        "* This creates a memory of previous steps.\n",
        "\n",
        "c) Output Layer\n",
        "\n",
        "* Produces output at each time step.\n",
        "\n",
        "* Depending on the task:\n",
        "\n",
        "  * Classification: one output at final step\n",
        "\n",
        "  * Sequence prediction: one output per time step\n",
        "\n",
        "  2. Key Characteristic: Recurrence\n",
        "\n",
        "The RNN updates its hidden state using:\n",
        "\n",
        "â„\n",
        "ğ‘¡=\n",
        "ğ‘“\n",
        "(\n",
        "ğ‘Š\n",
        "ğ‘¥\n",
        "ğ‘¡\n",
        "+\n",
        "ğ‘ˆ\n",
        "â„\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "1\n",
        "+\n",
        "ğ‘\n",
        ")\n",
        "\n",
        "Where:\n",
        "h\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        " = hidden state at time t\n",
        "x\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        " = input at time t\n",
        "1\n",
        "h\n",
        "tâˆ’1\n",
        "\tâ€‹\n",
        "\n",
        " = previous hidden state\n",
        "\n",
        "W,U = weight matrices\n",
        "\n",
        "\n",
        "f = activation function (tanh or ReLU)\n",
        "\n",
        "This enables RNNs to store past information and learn temporal dependencies.\n",
        "\n",
        "Functioning of an RNN (Step-by-Step)\n",
        "\n",
        "Step 1:\n",
        "\n",
        "Take the first input (e.g., first word) â†’ compute hidden state\n",
        "â„\n",
        "1\n",
        "h\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "Step 2:\n",
        "\n",
        "Next input + previous hidden state â†’ compute\n",
        "â„\n",
        "2\n",
        "h\n",
        "2\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "Step 3:\n",
        "\n",
        "Continue this process across the entire sequence.\n",
        "\n",
        "Step 4:\n",
        "\n",
        "Generate output using the final hidden state or each hidden state (depending on the task).\n",
        "\n",
        "This flow allows RNNs to understand context, such as:\n",
        "\n",
        "  * Meaning of a sentence\n",
        "\n",
        "  * Time dependencies in stock prices\n",
        "\n",
        "  * Speech signals\n",
        "\n",
        "4. Strengths of RNNs\n",
        "\n",
        "* Good for sequential and temporal data\n",
        "\n",
        "* Maintains memory of previous inputs\n",
        "\n",
        "* Useful for NLP tasks like:\n",
        "\n",
        "  * Language modeling\n",
        "\n",
        "  * Text generation\n",
        "\n",
        "  * Machine translation\n",
        "\n",
        "5. Limitations of RNNs\n",
        "\n",
        "* Suffer from vanishing and exploding gradient problems\n",
        "\n",
        "* Struggle to learn long-term dependencies\n",
        "\n",
        "* Replaced mostly by LSTMs, GRUs, and Transformers"
      ],
      "metadata": {
        "id": "MFOvJSx2qJPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5:** What is the key difference between LSTM and GRU networks in NLP\n",
        "applications?\n",
        "\n",
        "**Key Difference Between LSTM and GRU Networks**\n",
        "\n",
        "Both LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units) are advanced RNN architectures designed to solve the vanishing gradient problem and handle long-term dependencies.\n",
        "However, they differ in structure and complexity.\n",
        "\n",
        "1. Architectural Difference\n",
        "\n",
        "LSTM\n",
        "\n",
        "* nHas three gates:\n",
        "  * Input Gate\n",
        "  * Forget Gate\n",
        "  * Output Gate\n",
        "\n",
        "* Maintains two states:\n",
        "  * Hidden state (h)\n",
        "  * Cell state (c)\n",
        "\n",
        "GRU\n",
        "\n",
        "* Has two gates:\n",
        "  * Update Gate\n",
        "  * Reset Gate\n",
        "\n",
        "* Maintains only one state:\n",
        "  *Hidden state (h)\n",
        "\n",
        "GRU is a simplified version of LSTM with fewer parameters.\n",
        "\n",
        "2. Performance & Usage Differences\n",
        "\n",
        "LSTM\n",
        "\n",
        "  * More powerful and expressive due to two states.\n",
        "\n",
        "  * Better for very complex sequences or longer dependencies.\n",
        "\n",
        "  * Slightly slower due to more gates.\n",
        "\n",
        "GRU\n",
        "\n",
        "  * Faster to train because it has fewer parameters.\n",
        "\n",
        "  * Performs similarly or sometimes better on small datasets.\n",
        "\n",
        "  * Usually preferred when speed and efficiency matter."
      ],
      "metadata": {
        "id": "yD38clSZrc-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:** Write a Python program using TextBlob to perform sentiment analysis on the following paragraph of text:\n",
        "\n",
        "â€œI had a great experience using the new mobile banking app. The interface is intuitive, and customer support was quick to resolve my issue. However, the app did crash once during a transaction, which was frustrating\"\n",
        "\n",
        "Your program should print out the polarity and subjectivity scores.\n"
      ],
      "metadata": {
        "id": "yXEn1tPlr83K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"\"\"\n",
        "I had a great experience using the new mobile banking app.\n",
        "The interface is intuitive, and customer support was quick to resolve my issue.\n",
        "However, the app did crash once during a transaction, which was frustrating.\n",
        "\"\"\"\n",
        "\n",
        "# Create TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Get polarity and subjectivity\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "# Print results\n",
        "print(\"Polarity:\", polarity)\n",
        "print(\"Subjectivity:\", subjectivity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YokE3FKsKT7",
        "outputId": "0ec9cb53-c41a-4ee4-bdfa-d03f7ef83f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.21742424242424244\n",
            "Subjectivity: 0.6511363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7:** Given the sample paragraph below, perform string tokenization and frequency distribution using Python and NLTK:\n",
        "\n",
        "â€œNatural Language Processing (NLP) is a fascinating field that combines linguistics, computer science, and artificial intelligence. It enables machines to understand, interpret, and generate human language. Applications of NLP include chatbots, sentiment analysis, and machine translation. As technology advances, the role of NLP in modern solutions is becoming increasingly critical.â€\n"
      ],
      "metadata": {
        "id": "lVR5IER2sK_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Download required resources (run once)\n",
        "nltk.download('punkt_tab') # Changed from 'punkt' to 'punkt_tab' as per error message\n",
        "\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a fascinating field that combines linguistics,\n",
        "computer science, and artificial intelligence. It enables machines to understand,\n",
        "interpret, and generate human language. Applications of NLP include chatbots,\n",
        "sentiment analysis, and machine translation. As technology advances, the role of NLP\n",
        "in modern solutions is becoming increasingly critical.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\")\n",
        "print(tokens)\n",
        "\n",
        "# 2. Frequency Distribution\n",
        "freq_dist = FreqDist(tokens)\n",
        "\n",
        "print(\"\\nFrequency Distribution:\")\n",
        "for word, freq in freq_dist.most_common(10):\n",
        "    print(f\"{word} : {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm5J3SpMsUO8",
        "outputId": "0b9e0e91-7b75-4a0a-a462-fbb67df37759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'that', 'combines', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', '.', 'It', 'enables', 'machines', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'Applications', 'of', 'NLP', 'include', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.', 'As', 'technology', 'advances', ',', 'the', 'role', 'of', 'NLP', 'in', 'modern', 'solutions', 'is', 'becoming', 'increasingly', 'critical', '.']\n",
            "\n",
            "Frequency Distribution:\n",
            ", : 7\n",
            ". : 4\n",
            "NLP : 3\n",
            "and : 3\n",
            "is : 2\n",
            "of : 2\n",
            "Natural : 1\n",
            "Language : 1\n",
            "Processing : 1\n",
            "( : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8:** Implement a basic LSTM model in Keras for a text classification task using\n",
        "the following dummy dataset. Your model should classify sentences as either positive\n",
        "(1) or negative (0).\n",
        "# Dataset\n",
        "\n",
        "texts = [\n",
        "  \n",
        "  â€œI love this projectâ€, #Positive\n",
        "\n",
        "  â€œThis is an amazing experienceâ€, #Positive\n",
        "\n",
        "  â€œI hate waiting in lineâ€, #Negative\n",
        "\n",
        "  â€œThis is the worst serviceâ€, #Negative\n",
        "\n",
        "  â€œAbsolutely fantastic!â€ #Positive\n",
        "\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1]\n",
        "\n",
        "Preprocess the text, tokenize it, pad sequences, and build an LSTM model to train on this data. You may use Keras with TensorFlow backend.\n"
      ],
      "metadata": {
        "id": "rI1Ujmv3sXil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow if needed:\n",
        "# !pip install tensorflow\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1. Dummy Dataset\n",
        "# -----------------------------------------------------\n",
        "texts = [\n",
        "    \"I love this project\",              # Positive\n",
        "    \"This is an amazing experience\",    # Positive\n",
        "    \"I hate waiting in line\",           # Negative\n",
        "    \"This is the worst service\",        # Negative\n",
        "    \"Absolutely fantastic!\"             # Positive\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2. Tokenization\n",
        "# -----------------------------------------------------\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(\"Word Index:\", word_index)\n",
        "print(\"Sequences:\", sequences)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3. Padding Sequences\n",
        "# -----------------------------------------------------\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded_sequences)\n",
        "\n",
        "# Convert labels to numpy array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4. Build LSTM Model\n",
        "# -----------------------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=32, input_length=max_len))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5. Train the Model\n",
        "# -----------------------------------------------------\n",
        "history = model.fit(padded_sequences, labels, epochs=10, verbose=1)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6. Testing the model with a sample input\n",
        "# -----------------------------------------------------\n",
        "test_text = [\"I absolutely love this service\"]\n",
        "test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "test_pad = pad_sequences(test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "prediction = model.predict(test_pad)\n",
        "print(\"\\nPrediction Score:\", prediction)\n",
        "print(\"Sentiment:\", \"Positive\" if prediction > 0.5 else \"Negative\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXKEiot-s3lw",
        "outputId": "b766f373-eaa4-4a0a-8b06-1cfa306ffd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Index: {'this': 1, 'i': 2, 'is': 3, 'love': 4, 'project': 5, 'an': 6, 'amazing': 7, 'experience': 8, 'hate': 9, 'waiting': 10, 'in': 11, 'line': 12, 'the': 13, 'worst': 14, 'service': 15, 'absolutely': 16, 'fantastic': 17}\n",
            "Sequences: [[2, 4, 1, 5], [1, 3, 6, 7, 8], [2, 9, 10, 11, 12], [1, 3, 13, 14, 15], [16, 17]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 2  4  1  5  0]\n",
            " [ 1  3  6  7  8]\n",
            " [ 2  9 10 11 12]\n",
            " [ 1  3 13 14 15]\n",
            " [16 17  0  0  0]]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 0.6982\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2000 - loss: 0.6955\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6000 - loss: 0.6928\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6000 - loss: 0.6901\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6000 - loss: 0.6875\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6000 - loss: 0.6848\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6000 - loss: 0.6820\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6000 - loss: 0.6792\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6000 - loss: 0.6761\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6000 - loss: 0.6728\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step\n",
            "\n",
            "Prediction Score: [[0.52121705]]\n",
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9:** Using spaCy, build a simple NLP pipeline that includes tokenization, lemmatization, and entity recognition. Use the following paragraph as your dataset:\n",
        "\n",
        "â€œHomi Jehangir Bhaba was an Indian nuclear physicist who played a key role in the development of Indiaâ€™s atomic energy program. He was the founding director of the Tata Institute of Fundamental Research (TIFR) and was instrumental in establishing the Atomic Energy Commission of India.â€\n",
        "\n",
        "Write a Python program that processes this text using spaCy, then prints tokens, their lemmas, and any named entities found.\n"
      ],
      "metadata": {
        "id": "YF78zTnFtOOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy model if needed:\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"\"\"\n",
        "Homi Jehangir Bhaba was an Indian nuclear physicist who played a key role in the\n",
        "development of Indiaâ€™s atomic energy program. He was the founding director of the Tata\n",
        "Institute of Fundamental Research (TIFR) and was instrumental in establishing the\n",
        "Atomic Energy Commission of India.\n",
        "\"\"\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. Tokenization and Lemmatization\n",
        "# ---------------------------------------------------------\n",
        "print(\"Tokens and Lemmas:\\n\")\n",
        "for token in doc:\n",
        "    if not token.is_space:\n",
        "        print(f\"{token.text:20} -->  {token.lemma_}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Named Entity Recognition (NER)\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nNamed Entities Found:\\n\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text:40} -->  {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgRKhlEXtVqb",
        "outputId": "5e41ff2f-ed2f-4cb4-80d4-2e7f83199178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens and Lemmas:\n",
            "\n",
            "Homi                 -->  Homi\n",
            "Jehangir             -->  Jehangir\n",
            "Bhaba                -->  Bhaba\n",
            "was                  -->  be\n",
            "an                   -->  an\n",
            "Indian               -->  indian\n",
            "nuclear              -->  nuclear\n",
            "physicist            -->  physicist\n",
            "who                  -->  who\n",
            "played               -->  play\n",
            "a                    -->  a\n",
            "key                  -->  key\n",
            "role                 -->  role\n",
            "in                   -->  in\n",
            "the                  -->  the\n",
            "development          -->  development\n",
            "of                   -->  of\n",
            "India                -->  India\n",
            "â€™s                   -->  â€™s\n",
            "atomic               -->  atomic\n",
            "energy               -->  energy\n",
            "program              -->  program\n",
            ".                    -->  .\n",
            "He                   -->  he\n",
            "was                  -->  be\n",
            "the                  -->  the\n",
            "founding             -->  found\n",
            "director             -->  director\n",
            "of                   -->  of\n",
            "the                  -->  the\n",
            "Tata                 -->  Tata\n",
            "Institute            -->  Institute\n",
            "of                   -->  of\n",
            "Fundamental          -->  Fundamental\n",
            "Research             -->  Research\n",
            "(                    -->  (\n",
            "TIFR                 -->  TIFR\n",
            ")                    -->  )\n",
            "and                  -->  and\n",
            "was                  -->  be\n",
            "instrumental         -->  instrumental\n",
            "in                   -->  in\n",
            "establishing         -->  establish\n",
            "the                  -->  the\n",
            "Atomic               -->  Atomic\n",
            "Energy               -->  Energy\n",
            "Commission           -->  Commission\n",
            "of                   -->  of\n",
            "India                -->  India\n",
            ".                    -->  .\n",
            "\n",
            "Named Entities Found:\n",
            "\n",
            "Indian                                   -->  NORP\n",
            "India                                    -->  GPE\n",
            "the Tata\n",
            "Institute of Fundamental Research -->  ORG\n",
            "Atomic Energy Commission of India        -->  ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10:** You are working on a chatbot for a mental health platform. Explain how you would leverage LSTM or GRU networks along with libraries like spaCy or Stanford NLP to understand and respond to user input effectively. Detail your architecture, data preprocessing pipeline, and any ethical considerations.\n"
      ],
      "metadata": {
        "id": "filUzgqVtaxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. System Architecture Overview**\n",
        "\n",
        "A mental-health chatbot typically involves three major components:\n",
        "\n",
        "(1) NLP Understanding Block (spaCy / StanfordNLP)\n",
        "\n",
        "Used for:\n",
        "\n",
        "* Tokenization\n",
        "\n",
        "* Lemmatization\n",
        "\n",
        "* POS tagging\n",
        "\n",
        "* Dependency parsing\n",
        "\n",
        "* Named Entity Recognition (NER)\n",
        "\n",
        "* Detecting emotion-related keywords (e.g., â€œanxious,â€ â€œaloneâ€)\n",
        "\n",
        "(2) Deep Learning Module (LSTM or GRU)\n",
        "\n",
        "Used for:\n",
        "\n",
        "* Intent classification\n",
        "\n",
        "* Emotion detection\n",
        "\n",
        "* Generating context-aware responses\n",
        "\n",
        "* Predicting user sentiment over time\n",
        "\n",
        "(3) Response Generation Layer\n",
        "\n",
        "* Rule-based templates for clinical safety\n",
        "\n",
        "* Retrieval-based responses from curated mental-health resources\n",
        "\n",
        "* Escalation to human counselor when needed\n",
        "\n",
        "**2. Data Preprocessing Pipeline**\n",
        "\n",
        "To prepare the text for an LSTM/GRU model:\n",
        "\n",
        "Step 1: Text Cleaning\n",
        "\n",
        "  * Lowercasing\n",
        "\n",
        "  * Removing URLs, emojis, special characters\n",
        "\n",
        "  * Removing stopwords cautiously (e.g., keep â€œnot,â€ â€œneverâ€ for mental health context)\n",
        "\n",
        "Step 2: Tokenization (spaCy or StanfordNLP)\n",
        "\n",
        "  * Break sentences into tokens\n",
        "\n",
        "  * Identify parts of speech\n",
        "\n",
        "  * Extract meaningful phrases (â€œfeeling depressedâ€, â€œpanic attackâ€)\n",
        "\n",
        "Step 3: Lemmatization\n",
        "\n",
        "  * Convert â€œfeeling â†’ feelâ€, â€œcried â†’ cryâ€\n",
        "\n",
        "  * Helps generalize emotional expressions\n",
        "\n",
        "Step 4: Sequence Preparation\n",
        "\n",
        "  * Convert tokens to integers using Tokenizer\n",
        "\n",
        "  * Pad sequences for uniform shape\n",
        "\n",
        "Step 5: Labeling\n",
        "\n",
        "Train on categories such as:\n",
        "\n",
        "  * Stress\n",
        "\n",
        "  * Anxiety\n",
        "\n",
        "  * Depression indicators\n",
        "\n",
        "  * Seeking motivation\n",
        "\n",
        "  * Neutral conversation\n",
        "\n",
        "Step 6: Embedding Layer\n",
        "\n",
        "Use:\n",
        "\n",
        "  * GloVe embeddings\n",
        "\n",
        "  * Word2Vec\n",
        "\n",
        "  * Or spaCy vectors (300-dim)\n",
        "\n",
        "These embeddings help the LSTM/GRU understand emotional nuances."
      ],
      "metadata": {
        "id": "tztqiA8gtqu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "# !pip install spacy tensorflow\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. Load spaCy NLP model\n",
        "# ---------------------------------------------------------\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Dummy mental-health dataset (intent classification)\n",
        "# ---------------------------------------------------------\n",
        "texts = [\n",
        "    \"I feel very sad and alone\",\n",
        "    \"I'm stressed because of exams\",\n",
        "    \"I had a good day today\",\n",
        "    \"Life feels overwhelming right now\",\n",
        "    \"I am happy and grateful\",\n",
        "    \"I need some motivation\",\n",
        "    \"I am anxious about my future\"\n",
        "]\n",
        "\n",
        "# Labels (0 = Negative emotions, 1 = Positive/Neutral)\n",
        "labels = [0, 0, 1, 0, 1, 1, 0]\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Preprocessing with spaCy (tokenization + lemmatization)\n",
        "# ---------------------------------------------------------\n",
        "def spacy_preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_.lower() for token in doc if not token.is_stop])\n",
        "\n",
        "processed_texts = [spacy_preprocess(t) for t in texts]\n",
        "print(\"Processed Texts:\", processed_texts)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Tokenization + Sequence padding\n",
        "# ---------------------------------------------------------\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(processed_texts)\n",
        "\n",
        "seqs = tokenizer.texts_to_sequences(processed_texts)\n",
        "max_len = max(len(s) for s in seqs)\n",
        "padded_seqs = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Build LSTM Model\n",
        "# ---------------------------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                    output_dim=32,\n",
        "                    input_length=max_len))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. Train model\n",
        "# ---------------------------------------------------------\n",
        "model.fit(padded_seqs, labels, epochs=10, verbose=1)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7. Test chatbot understanding\n",
        "# ---------------------------------------------------------\n",
        "def predict_intent(msg):\n",
        "    processed = spacy_preprocess(msg)\n",
        "    seq = tokenizer.texts_to_sequences([processed])\n",
        "    pad = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    pred = model.predict(pad)[0][0]\n",
        "    return \"Positive/Neutral\" if pred > 0.5 else \"Negative Emotion\"\n",
        "\n",
        "test_message = \"I feel hopeless and tired\"\n",
        "print(\"\\nUser:\", test_message)\n",
        "print(\"Predicted Intent:\", predict_intent(test_message))\n"
      ],
      "metadata": {
        "id": "c4xyu-BsuVeZ",
        "outputId": "695f6bdd-a203-4961-eab0-aa70714c5a9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Texts: ['feel sad', 'stress exam', 'good day today', 'life feel overwhelming right', 'happy grateful', 'need motivation', 'anxious future']\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4286 - loss: 0.6932\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7143 - loss: 0.6917\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5714 - loss: 0.6902\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5714 - loss: 0.6886\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5714 - loss: 0.6871\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5714 - loss: 0.6854\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5714 - loss: 0.6836\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.5714 - loss: 0.6817\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5714 - loss: 0.6796\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5714 - loss: 0.6773\n",
            "\n",
            "User: I feel hopeless and tired\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
            "Predicted Intent: Negative Emotion\n"
          ]
        }
      ]
    }
  ]
}